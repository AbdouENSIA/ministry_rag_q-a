{"id":null,"metadata":{"producer":"Skia/PDF m97","creator":"Chromium","creationdate":"2025-03-21T17:27:11+00:00","moddate":"2025-03-21T17:27:11+00:00","source":"c:\\Users\\wwwab\\Development\\ministry_rag_q-a\\knowledge_base\\raw_data\\documents\\group_project_rag.pdf","total_pages":14,"page":0,"page_label":"1","file_name":"group_project_rag.pdf","file_type":".pdf"},"page_content":"Page 1 of 14Ministry Regulation Q&A System: Project Plan\nIntroduction\nThe Ministry Regulation Q&A System is a cutting-edge platform designed to provide accurate,\naccessible, and ministry-worthy answers to questions about regulatory policies, speci\u0000cally targeting\nArabic-speaking users. By employing Retrieval-Augmented Generation (RAG) technology, the system\nprocesses o\u0000cial 2024 ministry regulation documents to deliver concise, contextually grounded\nresponses in Arabic. This project serves students, educators, and the general public, simplifying access\nto complex regulatory information while maintaining high standards of quality, usability, and scalability.\nProject Objectives\nDeliver a fully functional prototype by April 16, 2025, utilizing 2024 ministry regulation documents\nas the primary knowledge base.\nDevelop a robust, scalable, and secure backend using Python technologies that adhere to\nSoftware Engineering (SE) best practices and SOLID principles.\nCreate an intuitive, Arabic right-to-left (RTL) compatible frontend with a seamless user\nexperience.\nEnsure responses are accurate, relevant, and derived from o\u0000cial sources, meeting ministry\nstandards.\nFoster a collaborative team environment where all \u0000ve members contribute equally to a cohesive\ndeliverable.\nTeam Members\nAinouche Abderahmane\nMoulahcene Riadh\nZamoum Abdelhakim\nGuerroudj Abdennour\nMestouri Oussama\nTechnology Stack\nThe technology stack is carefully selected to balance performance, scalability, Arabic language support,\nand \u0000exibility for experimentation. Versions re\u0000ect the latest stable releases as of March 21, 2025,","type":"Document"}
{"id":null,"metadata":{"producer":"Skia/PDF m97","creator":"Chromium","creationdate":"2025-03-21T17:27:11+00:00","moddate":"2025-03-21T17:27:11+00:00","source":"c:\\Users\\wwwab\\Development\\ministry_rag_q-a\\knowledge_base\\raw_data\\documents\\group_project_rag.pdf","total_pages":14,"page":1,"page_label":"2","file_name":"group_project_rag.pdf","file_type":".pdf"},"page_content":"Page 2 of 14sourced from o\u0000cial repositories (e.g., PyPI, npm). Each technology’s purpose and rationale are\nexplained thoroughly to justify its inclusion.\nBackend Technologies\nTechnology/Package Version Purpose RationaleDocumentation\nLink\nFastAPI 0.115.0High-\nperformance,\nasynchronous\nAPI\nframeworkChosen for its speed (async\nsupport), automatic OpenAPI\ngeneration, and ease of scaling\nwith Python’s ecosystem. Ideal\nfor real-time Q&A responses\nand adheres to SOLID’s\nDependency Inversion by\nsupporting dependency\ninjection.FastAPI Docs\nLangChain 0.3.1Framework\nfor building\nRAG pipelinesProvides a modular, extensible\nframework for RAG, supporting\nmultiple LLMs and vector\nstores. Its abstraction layers\nalign with SOLID’s Open/Closed\nprinciple, allowing easy LLM\nswapping and scalability\nthrough chaining components.LangChain\nDocs\nLangGraph 0.2.23Advanced\nwork\u0000ows for\ncomplex\nquery\nhandlingExtends LangChain with graph-\nbased work\u0000ows, enabling\nmulti-step reasoning (e.g.,\nfollow-up questions). Chosen\nfor \u0000exibility and scalability,\nsupporting SOLID’s Single\nResponsibility by isolating\nwork\u0000ow logic.LangGraph\nDocs\nLangChain-Groq 0.2.0Integration\nwith Groq’s\nLLMsFacilitates experimentation\nwith Groq LLMs (e.g., Llama 3\n70B). Its modular design allows\nseamless swapping with other\nLLM providers (e.g., Google),\nsupporting SOLID’s\nOpen/Closed principle.LangChain-\nGroq Docs\nSentence\nTransformers3.1.1Multilingual\nembeddings\nfor Arabic\ntextOffers robust multilingual\nembeddings, critical for Arabic\ndocument retrieval in RAG.\nChosen for its proven\nperformance with Arabic (e.g.,\nparaphrase-\nmultilingual-MiniLM-\nL12-v2 ), ensuring accurate\nsimilarity search and scalability\nin vector storage.Hugging Face\nDocs","type":"Document"}
{"id":null,"metadata":{"producer":"Skia/PDF m97","creator":"Chromium","creationdate":"2025-03-21T17:27:11+00:00","moddate":"2025-03-21T17:27:11+00:00","source":"c:\\Users\\wwwab\\Development\\ministry_rag_q-a\\knowledge_base\\raw_data\\documents\\group_project_rag.pdf","total_pages":14,"page":2,"page_label":"3","file_name":"group_project_rag.pdf","file_type":".pdf"},"page_content":"Page 3 of 14Technology/Package Version Purpose RationaleDocumentation\nLink\nSupabase Python\nClient2.7.4Database and\nvector\nstorage\nmanagementProvides a Python interface to\nSupabase, enabling seamless\nintegration with PostgreSQL\nand pgvector. Chosen for its\nsimplicity, real-time\ncapabilities, and scalability,\naligning with SOLID’s\nDependency Inversion via\nabstracted DB access.Supabase\nPython Docs\nPydantic 2.9.2Data\nvalidation and\nsettings\nmanagementEnsures type safety and\ncon\u0000guration management\n(e.g., API payloads, env vars).\nChosen for its robust\nvalidation, supporting SOLID’s\nSingle Responsibility by\nisolating data modeling from\nbusiness logic, and scalability\nthrough structured data\nhandling.Pydantic Docs\npython-dotenv 1.0.1Environment\nvariable\nmanagementManages sensitive\ncon\u0000guration (e.g., API keys)\nsecurely outside code. Chosen\nfor its simplicity and alignment\nwith SE best practices,\nensuring \u0000exibility and\nscalability by decoupling con\u0000g\nfrom implementation.python-dotenv\nDocs\nUvicorn 0.30.6ASGI server\nfor running\nFastAPILightweight, high-\nperformance server for\nFastAPI. Chosen for its async\ncapabilities, ensuring\nscalability under high load, and\ncompatibility with Python’s\necosystem, supporting SOLID’s\nDependency Inversion via\ncon\u0000gurable deployment.Uvicorn Docs\nFrontend Technologies\nTechnology/Package Version Purpose RationaleDocumentation\nLink","type":"Document"}
{"id":null,"metadata":{"producer":"Skia/PDF m97","creator":"Chromium","creationdate":"2025-03-21T17:27:11+00:00","moddate":"2025-03-21T17:27:11+00:00","source":"c:\\Users\\wwwab\\Development\\ministry_rag_q-a\\knowledge_base\\raw_data\\documents\\group_project_rag.pdf","total_pages":14,"page":3,"page_label":"4","file_name":"group_project_rag.pdf","file_type":".pdf"},"page_content":"Page 4 of 14Technology/Package Version Purpose RationaleDocumentation\nLink\nNext.js 14.2.14React\nframework for\nbuilding the UIProvides server-side\nrendering, static site\ngeneration, and a robust\necosystem for UI\ndevelopment. Chosen for its\nscalability, ease of\ndeployment (e.g., Vercel), and\nsupport for RTL styling,\ncritical for Arabic usability.Next.js Docs\nnpx create-agent-\nchat-app-Template for\nchat\napplication UIA LangChain-provided\ntemplate for rapid chat UI\nprototyping. Chosen to\naccelerate frontend\ndevelopment while ensuring\ncompatibility with\nLangChain’s backend,\nsupporting scalability and\nteam collaboration on UI\ncustomization.LangChain Chat\nApp\nSupabase JS Client 2.45.4Authentication\nand chat\nhistory\nmanagementEnables frontend integration\nwith Supabase for user auth\nand real-time data. Chosen for\nits simplicity, real-time\nupdates, and scalability,\naligning with SOLID’s\nDependency Inversion by\nabstracting auth logic.Supabase JS\nDocs\nDatabase Technologies\nTechnology/Package Version Purpose RationaleDocumentation\nLink\nSupabase -PostgreSQL\ndatabase\nwith\npgvector\nextensionOpen-source, scalable\nalternative to Firebase with\nPostgreSQL backend. Chosen for\nits vector search (pgvector), real-\ntime capabilities, and built-in\nauth, ensuring scalability and\nSOLID’s Single Responsibility by\nisolating data storage.Supabase Docs","type":"Document"}
{"id":null,"metadata":{"producer":"Skia/PDF m97","creator":"Chromium","creationdate":"2025-03-21T17:27:11+00:00","moddate":"2025-03-21T17:27:11+00:00","source":"c:\\Users\\wwwab\\Development\\ministry_rag_q-a\\knowledge_base\\raw_data\\documents\\group_project_rag.pdf","total_pages":14,"page":4,"page_label":"5","file_name":"group_project_rag.pdf","file_type":".pdf"},"page_content":"Page 5 of 14Technology/Package Version Purpose RationaleDocumentation\nLink\npgvector 0.7.4Vector\nsimilarity\nsearch for\nRAGExtends PostgreSQL with vector\noperations for e\u0000cient similarity\nsearch in RAG. Chosen for its\nperformance, integration with\nSupabase, and scalability,\nsupporting SOLID’s Open/Closed\nprinciple by allowing vector store\nenhancements.pgvector\nGitHub\nLarge Language Model (LLM) Options\nModel\nOptionsProvider Purpose RationaleDocumentation\nLink\nGroq\nLLMs\n(e.g.,\nLlama\n3 70B)GroqFast,\nmultilingual\nLLMs for\nexperimentationGroq offers high-speed inference, ideal\nfor real-time Q&A. Llama 3 70B is a\nstarting point due to its multilingual\ncapabilities, but we’ll experiment with\nothers for Arabic performance. Chosen\nfor speed and \u0000exibility.Groq Docs\nGoogle\nGemini\n2.0GoogleAlternative LLM\nfor\nexperimentationGoogle’s latest model (assumed available\nby 2025) may offer superior Arabic\nsupport. Chosen for its potential\nrobustness and integration with Google’s\necosystem, ensuring \u0000exibility in LLM\nswapping.Google AI Docs\nOthers\n(TBD)VariousAdditional LLMs\nfor testingWe’ll explore other providers (e.g.,\nHugging Face models) to compare\nperformance. Flexibility is key, aligning\nwith SOLID’s Open/Closed principle for\nseamless LLM substitution.TBD based on\nexperimentation\nLLM Flexibility\nWhy Not De\u0000nitive: We will experiment with multiple LLMs (Groq’s Llama 3 70B, Google Gemini\n2.0, etc.) to determine the best \u0000t for Arabic Q&A. The backend will use an abstraction layer (e.g.,\nLangChain’s LLM interface) to swap LLMs seamlessly by updating con\u0000guration (e.g., API keys,\nmodel names) without altering core logic, adhering to SOLID’s Open/Closed and Dependency\nInversion principles.\nProject Architecture\nThe system comprises three interconnected components designed for scalability and modularity:","type":"Document"}
{"id":null,"metadata":{"producer":"Skia/PDF m97","creator":"Chromium","creationdate":"2025-03-21T17:27:11+00:00","moddate":"2025-03-21T17:27:11+00:00","source":"c:\\Users\\wwwab\\Development\\ministry_rag_q-a\\knowledge_base\\raw_data\\documents\\group_project_rag.pdf","total_pages":14,"page":5,"page_label":"6","file_name":"group_project_rag.pdf","file_type":".pdf"},"page_content":"Page 6 of 14Work\u0000ow\n\u0000. User Interaction: Users input Arabic queries via the Next.js frontend chat interface.\n\u0000. API Communication: Frontend sends HTTP requests to FastAPI endpoints.\n\u0000. RAG Processing: LangChain retrieves relevant document chunks from Supabase, and the\nselected LLM generates answers.\n\u0000. Response Delivery: Answers are returned to the frontend, displayed with Arabic RTL support.\n\u0000. Data Persistence: Queries, responses, and user data are stored in Supabase for history and\nauditing.\nBackend Components\nDocument Ingestion:\nProcesses ministry documents, splits them into chunks, and generates embeddings for\nvector search.\nStores data in Supabase with pgvector for e\u0000cient retrieval.\nRAG Pipeline:\nRetrieves document chunks based on query embeddings and generates responses using a\ncon\u0000gurable LLM.\nSupports multi-step work\u0000ows via LangGraph for complex queries.\nAPI:\nExposes endpoints (/qa  for queries, /history  for chat logs) with Supabase JWT\nauthentication for security.\nFrontend Components\nChat Interface:\nBuilt with Next.js and customized from the \"npx create-agent-chat-app\" template.\nEnsures real-time interaction and Arabic RTL compatibility.\nAuthentication:\nIntegrates Supabase JS client for user login, registration, and session management.\nDatabase Schema\nTable Columns Purpose\nusers id (UUID), email  (string), created_at  (timestamp)Manages user\naccounts\nchat_sessions id (UUID), user_id  (UUID), timestamp  (timestamp)Tracks user\nchat sessions","type":"Document"}
{"id":null,"metadata":{"producer":"Skia/PDF m97","creator":"Chromium","creationdate":"2025-03-21T17:27:11+00:00","moddate":"2025-03-21T17:27:11+00:00","source":"c:\\Users\\wwwab\\Development\\ministry_rag_q-a\\knowledge_base\\raw_data\\documents\\group_project_rag.pdf","total_pages":14,"page":6,"page_label":"7","file_name":"group_project_rag.pdf","file_type":".pdf"},"page_content":"Page 7 of 14Table Columns Purpose\nmessagesid (UUID), session_id  (UUID), query  (text),\nresponse  (text), timestamp  (timestamp)Stores chat\nhistory\ndocuments id (UUID), content  (text), metadata  (JSON)Holds\ndocument\nchunks\nembeddings id (UUID), vector  (vector), document_id  (UUID)Stores vector\nembeddings\nScalability Features\nBackend: Async FastAPI and modular LangChain components handle high concurrency.\nDatabase: Supabase’s PostgreSQL with pgvector scales with user load and vector data.\nFrontend: Next.js supports server-side rendering and static generation for performance.\nDevelopment Plan\nEach phase includes speci\u0000c tasks and deliverables.\nPhase 1: Database Setup\nTasks: Set up Supabase project, enable pgvector, create and test database schema.\nDeliverables: Fully operational Supabase instance with all tables con\u0000gured.\nPhase 2: Document Ingestion\nTasks: Collect 2024 ministry documents, preprocess them, implement ingestion pipeline, store\nembeddings in Supabase.\nDeliverables: Ingested documents ready for RAG processing.\nPhase 3: RAG Pipeline\nTasks: Develop RAG system, integrate initial LLM (e.g., Groq’s Llama 3 70B), test with Arabic\nqueries, experiment with alternative LLMs (e.g., Gemini 2.0).\nDeliverables: Working RAG pipeline with \u0000exible LLM con\u0000guration.\nPhase 4: Backend API","type":"Document"}
{"id":null,"metadata":{"producer":"Skia/PDF m97","creator":"Chromium","creationdate":"2025-03-21T17:27:11+00:00","moddate":"2025-03-21T17:27:11+00:00","source":"c:\\Users\\wwwab\\Development\\ministry_rag_q-a\\knowledge_base\\raw_data\\documents\\group_project_rag.pdf","total_pages":14,"page":7,"page_label":"8","file_name":"group_project_rag.pdf","file_type":".pdf"},"page_content":"Page 8 of 14Tasks: Build FastAPI server, implement endpoints, secure with JWT, add logging and error\nhandling.\nDeliverables: Secure, functional API integrated with RAG.\nPhase 5: Frontend Development\nTasks: Set up Next.js, customize chat template, integrate with backend and Supabase, style for\nArabic RTL.\nDeliverables: Fully functional chat UI.\nPhase 6: Testing and Deployment\nTasks: Write comprehensive tests, deploy backend and frontend to cloud platforms, optimize\nperformance.\nDeliverables: Deployed, tested prototype.\nPhase 7: Final Review and Buffer\nTasks: Conduct \u0000nal testing, re\u0000ne based on feedback, prepare documentation and submission.\nDeliverables: Polished prototype ready for April 16, 2025.\nTeam Responsibilities\nWork is divided equally among \u0000ve members, with speci\u0000c primary roles and shared frontend\ncontributions. Each role aligns with SOLID principles for modularity and scalability.\nAinouche Abderahmane: RAG Pipeline Lead\nPrimary Responsibilities:\nDesign and implement the RAG pipeline using LangChain and LangGraph.\nIntegrate initial LLM (Groq’s Llama 3 70B) and create an abstraction layer for swapping LLMs\n(e.g., Google Gemini 2.0).\nTest Arabic query performance and re\u0000ne retrieval/generation logic.\nExperiment with multiple LLMs, documenting performance metrics (e.g., speed, accuracy).\nEffort: 2 weeks development, 1 week testing and experimentation.\nFrontend Contribution: Collaborate on integrating RAG responses into the Next.js UI, ensuring\nsmooth data \u0000ow.\nMoulahcene Riadh: Database and Ingestion Lead","type":"Document"}
{"id":null,"metadata":{"producer":"Skia/PDF m97","creator":"Chromium","creationdate":"2025-03-21T17:27:11+00:00","moddate":"2025-03-21T17:27:11+00:00","source":"c:\\Users\\wwwab\\Development\\ministry_rag_q-a\\knowledge_base\\raw_data\\documents\\group_project_rag.pdf","total_pages":14,"page":8,"page_label":"9","file_name":"group_project_rag.pdf","file_type":".pdf"},"page_content":"Page 9 of 14Primary Responsibilities:\nSet up the Supabase project, enable pgvector, and con\u0000gure all database tables.\nCollect and preprocess 2024 ministry documents (e.g., PDFs, text \u0000les).\nImplement the document ingestion pipeline, ensuring embeddings are generated and stored\ne\u0000ciently.\nTest database performance under load to ensure scalability.\nEffort: 1 week database setup, 2 weeks ingestion development.\nFrontend Contribution: Assist with Supabase JS client integration for chat history and\nauthentication.\nZamoum Abdelhakim: Backend API Lead\nPrimary Responsibilities:\nDevelop the FastAPI server, implementing /qa  and /history  endpoints.\nSecure endpoints with Supabase JWT authentication, ensuring user data protection.\nAdd comprehensive logging and error handling for debugging and scalability.\nTest API performance with simulated user tra\u0000c.\nEffort: 2 weeks API development, 1 week testing and re\u0000nement.\nFrontend Contribution: Ensure API endpoints align with frontend requirements, assisting with API\ncall integration.\nMestouri Oussama: Testing and Deployment Lead\nPrimary Responsibilities:\nDevelop a testing strategy, writing unit and integration tests for backend and frontend.\nDeploy the backend to a cloud platform (e.g., Railway) and frontend to Vercel.\nMonitor and optimize deployed system performance (e.g., response time, scalability).\nDocument deployment process for team reference.\nEffort: 1 week testing setup, 2 weeks deployment and optimization.\nFrontend Contribution: Test UI functionality, responsiveness, and RTL rendering.\nGuerroudj Abdennour: Frontend Development Lead\nPrimary Responsibilities:\nSet up the Next.js project using \"npx create-agent-chat-app\" as a base.\nCustomize the chat interface, integrating with FastAPI and Supabase JS client.\nLead RTL styling and Arabic usability enhancements, ensuring a ministry-worthy UI.\nCoordinate team frontend efforts for consistency.\nEffort: 1 week setup, 2 weeks integration and styling.\nFrontend Contribution: Oversee UI development, ensuring all team inputs are cohesive.","type":"Document"}
{"id":null,"metadata":{"producer":"Skia/PDF m97","creator":"Chromium","creationdate":"2025-03-21T17:27:11+00:00","moddate":"2025-03-21T17:27:11+00:00","source":"c:\\Users\\wwwab\\Development\\ministry_rag_q-a\\knowledge_base\\raw_data\\documents\\group_project_rag.pdf","total_pages":14,"page":9,"page_label":"10","file_name":"group_project_rag.pdf","file_type":".pdf"},"page_content":"Page 10 of 14Shared Frontend Responsibilities\nAll Members:\nContribute to Next.js frontend development, including chat components, authentication\n\u0000ows, and RTL styling.\nParticipate in weekly UI sync meetings to integrate backend components and test usability.\nReview and re\u0000ne the UI for a seamless Arabic user experience.\nDevelopment Instructions\nThese instructions are explicit, removing ambiguity, and tailored for each member on Windows.\nAinouche Abderahmane: RAG Pipeline Lead\nSteps:\n\u0000. Ensure LangChain tools are installed: Open Command Prompt in backend/ , run pip\nlist  to verify langchain , langchain-groq , langchain-community .\n\u0000. Obtain API keys for Groq (from groq.com) and Google Gemini (from ai.google)—store in\nbackend/.env  (e.g., GROQ_API_KEY=xxx , GOOGLE_API_KEY=yyy ).\n\u0000. Develop the RAG pipeline in backend/src/core/rag.py , creating an LLM abstraction\nlayer (e.g., con\u0000g \u0000le or class) to switch between Groq, Google, and other LLMs by changing\nkeys/model names.\n\u0000. Test with Arabic queries: Run pipeline manually with sample questions (e.g., “اﻟﺟدﯾدة  اﻟﻠواﺋﺢ  ھﻲ  ﻣﺎ\n؟2024 ﻟﻌﺎمand log performance metrics (speed, accuracy).\n\u0000. Experiment with at least three LLMs (e.g., Llama 3 70B, Gemini 2.0, one other), documenting\nresults in a shared doc.\n\u0000. Collaborate on UI: In frontend/pages/ , integrate RAG responses into the chat\ncomponent, testing real-time display.\nTools: Python, VS Code, Command Prompt, Groq/Google APIs.\nMoulahcene Riadh: Database and Ingestion Lead\nSteps:\n\u0000. Create a Supabase project: Visit supabase.com, sign up, create a new project, note the URL\nand anon key, store in backend/.env  (e.g., SUPABASE_URL=xxx ,\nSUPABASE_KEY=yyy ).\n\u0000. Enable pgvector: In Supabase dashboard, go to SQL Editor, run CREATE EXTENSION\npgvector; , verify with SELECT * FROM pg_extension; .","type":"Document"}
{"id":null,"metadata":{"producer":"Skia/PDF m97","creator":"Chromium","creationdate":"2025-03-21T17:27:11+00:00","moddate":"2025-03-21T17:27:11+00:00","source":"c:\\Users\\wwwab\\Development\\ministry_rag_q-a\\knowledge_base\\raw_data\\documents\\group_project_rag.pdf","total_pages":14,"page":10,"page_label":"11","file_name":"group_project_rag.pdf","file_type":".pdf"},"page_content":"Page 11 of 14\u0000. Set up tables: Use Supabase dashboard’s Table Editor to create users ,\nchat_sessions , messages , documents , embeddings  with speci\u0000ed columns, or\nrun SQL scripts provided in team docs.\n\u0000. Collect 2024 ministry documents (e.g., PDFs from ministry sources), convert to text if\nneeded (manual or via tools like Adobe Acrobat), save in backend/data/ .\n\u0000. Develop ingestion pipeline in backend/src/core/ingestion.py , testing with a\nsample document to ensure chunks and embeddings are stored in Supabase.\n\u0000. Test database scalability: Insert 100+ sample records, query with SELECT * FROM\nembeddings LIMIT 10;  in Supabase SQL Editor to verify.\n\u0000. Assist with UI: In frontend/lib/supabase.js , con\u0000gure Supabase JS client with your\nproject’s URL and key, test chat history retrieval.\nTools: Supabase dashboard, Python, VS Code, Command Prompt.\nZamoum Abdelhakim: Backend API Lead\nSteps:\n\u0000. Verify FastAPI setup: In backend/ , run pip list  to con\u0000rm fastapi , uvicorn  are\ninstalled.\n\u0000. Develop API in backend/src/routers/api.py  and backend/src/main.py ,\nimplementing /qa  (POST) and /history  (GET) endpoints.\n\u0000. Secure with Supabase JWT: Use Supabase auth token from frontend, validate in API using\nSupabase Python client’s auth methods.\n\u0000. Add logging: Con\u0000gure Python’s logging  module to log requests/errors to\nbackend/logs/api.log .\n\u0000. Test locally: Run uvicorn src.main:app --reload  in backend/ , use a tool like\nPostman to send sample requests (e.g., POST http://localhost:8000/qa  with\n{\"query\": \"ﻣﺎ ھﻲ اﻟﻘﻮاﻧﯿﻦ؟}).\n\u0000. Collaborate on UI: In frontend/api/ , ensure API calls match endpoint specs, test with\nsample queries.\nTools: FastAPI, Postman, VS Code, Command Prompt.\nMestouri Oussama: Testing and Deployment Lead\nSteps:\n\u0000. Install testing tools: In backend/ , run pip install pytest  to con\u0000rm installation.\n\u0000. Develop tests: Create backend/tests/test_rag.py , test_api.py , etc., covering\nRAG, API, and ingestion (e.g., mock Supabase responses, test LLM outputs).\n\u0000. Set up Railway: Sign up at railway.app, link Git repo, con\u0000gure backend/  deployment with\nProcfile  (e.g., web: uvicorn src.main:app --host 0.0.0.0 --port","type":"Document"}
{"id":null,"metadata":{"producer":"Skia/PDF m97","creator":"Chromium","creationdate":"2025-03-21T17:27:11+00:00","moddate":"2025-03-21T17:27:11+00:00","source":"c:\\Users\\wwwab\\Development\\ministry_rag_q-a\\knowledge_base\\raw_data\\documents\\group_project_rag.pdf","total_pages":14,"page":11,"page_label":"12","file_name":"group_project_rag.pdf","file_type":".pdf"},"page_content":"Page 12 of 14$PORT ).\n\u0000. Set up Vercel: Sign up at vercel.com, link frontend/  repo, run vercel --prod  in\nfrontend/  to deploy.\n\u0000. Test deployed system: Use Postman or browser to hit deployed endpoints (e.g., <railway-\nurl>/qa ), verify UI at <vercel-url> .\n\u0000. Optimize: Monitor Railway logs, adjust Supabase indexing if slow, document \u0000ndings.\n\u0000. Test UI: In frontend/ , verify chat functionality and RTL rendering post-deployment.\nTools: Pytest, Railway CLI, Vercel CLI, VS Code, Command Prompt.\nGuerroudj Abdennour: Frontend Development Lead\nSteps:\n\u0000. Verify Node.js: Run node --version  to con\u0000rm 14+.\n\u0000. Set up frontend: In frontend/ , run npx create-agent-chat-app , select default\noptions, then npm install  to set up.\n\u0000. Con\u0000gure Supabase: In frontend/lib/supabase.js , add Supabase URL and key from\nMoulahcene’s setup, test auth with npm run dev .\n\u0000. Integrate API: In frontend/api/ , create functions to call Zamoum’s endpoints (e.g.,\nfetch('/qa', { method: 'POST', body: JSON.stringify({ query })\n})).\n\u0000. Style RTL: In frontend/styles/global.css , add body { direction: rtl;\nfont-family: Amiri; } , test with Arabic text.\n\u0000. Lead UI sync: Schedule weekly meetings, assign UI tasks (e.g., chat input to Ainouche,\nhistory to Moulahcene), review progress.\n\u0000. Test locally: Run npm run dev  in frontend/ , visit http://localhost:3000  to\nverify.\nTools: Next.js, npm, VS Code, Command Prompt.\nResources and Documentation\nO\u0000cial Documentation\nFastAPI: Comprehensive guide for API development.\nLangChain: RAG pipeline and LLM integration details.\nLangGraph: Work\u0000ow design and examples.\nSupabase: Database setup, auth, and real-time features.\nNext.js: Frontend development and deployment.\nGroq: LLM access and con\u0000guration.","type":"Document"}
{"id":null,"metadata":{"producer":"Skia/PDF m97","creator":"Chromium","creationdate":"2025-03-21T17:27:11+00:00","moddate":"2025-03-21T17:27:11+00:00","source":"c:\\Users\\wwwab\\Development\\ministry_rag_q-a\\knowledge_base\\raw_data\\documents\\group_project_rag.pdf","total_pages":14,"page":12,"page_label":"13","file_name":"group_project_rag.pdf","file_type":".pdf"},"page_content":"Page 13 of 14Course Resources (Assumed from Abdelhakim Cheriet’s Course)\nAI and NLP: Concepts of RAG, embeddings, and LLMs for Arabic processing.\nWeb Development: RESTful API design and React fundamentals.\nDatabases: PostgreSQL basics and vector storage techniques.\nOnline Resources\nHugging Face Sentence Transformers: Latest embedding models for Arabic.\npgvector GitHub: Vector search optimization tips.\nArabic NLP Research (ArabicaQA): Dataset and benchmarks for Arabic Q&A testing.\nScalability and SOLID Adherence\nScalability:\nBackend uses async FastAPI and Supabase’s real-time features to handle high user loads.\nDatabase leverages pgvector indexing for e\u0000cient vector searches.\nFrontend employs Next.js’s server-side rendering for performance.\nSOLID Principles:\nSingle Responsibility: Each component (ingestion, RAG, API) has one clear purpose.\nOpen/Closed: LLM abstraction allows extension without modifying core logic.\nLiskov Substitution: Future LLM or DB clients can replace current ones seamlessly.\nInterface Segregation: API and DB clients expose only necessary methods.\nDependency Inversion: Dependencies (e.g., Supabase client, LLM con\u0000g) are injected, not\nhardcoded.\nChallenges and Solutions\nChallenge: Variable Arabic LLM performance.\nSolution: Experiment with multiple LLMs, re\u0000ne embeddings, and document results.\nChallenge: High query latency.\nSolution: Optimize pgvector indexing, cache frequent queries, and scale backend with cloud\nresources.\nChallenge: Team coordination.\nSolution: Weekly syncs, shared docs, and clear task ownership.\nConclusion","type":"Document"}
{"id":null,"metadata":{"producer":"Skia/PDF m97","creator":"Chromium","creationdate":"2025-03-21T17:27:11+00:00","moddate":"2025-03-21T17:27:11+00:00","source":"c:\\Users\\wwwab\\Development\\ministry_rag_q-a\\knowledge_base\\raw_data\\documents\\group_project_rag.pdf","total_pages":14,"page":13,"page_label":"14","file_name":"group_project_rag.pdf","file_type":".pdf"},"page_content":"Page 14 of 14This detailed plan ensures a scalable, ministry-worthy Q&A system by April 16, 2025. With explicit roles,\n\u0000exible LLM experimentation, and adherence to SOLID principles, Ainouche, Moulahcene, Zamoum,\nGuerroudj, and Mestouri will deliver a high-quality prototype under Abdelhakim Cheriet’s guidance.\nTeam Commitment: We pledge to collaborate, innovate, and exceed expectations.","type":"Document"}
